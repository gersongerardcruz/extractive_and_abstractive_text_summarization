{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Capstone Project Streamlit - {Cruz, Gerson}.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPVto3U79Wx97oQqrvPcTge"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YiCOOzNBJUMk","executionInfo":{"status":"ok","timestamp":1647693216121,"user_tz":-480,"elapsed":20301,"user":{"displayName":"Gerson Cruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07825640613715802477"}},"outputId":"14198416-53a2-4104-a136-9dd6fb04eca5"},"outputs":[{"output_type":"stream","name":"stdout","text":["/\n","Mounted at /content/gdrive\n"]}],"source":["%cd ..\n","from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","!ln -s /content/gdrive/My\\ Drive/ /mydrive"]},{"cell_type":"code","source":["%cd /mydrive/Omdena\\ School/Solving\\ Business\\ Problems\\ with\\ NLP/Capstone\\ Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ojgxh9h8JXbk","executionInfo":{"status":"ok","timestamp":1647693216585,"user_tz":-480,"elapsed":466,"user":{"displayName":"Gerson Cruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07825640613715802477"}},"outputId":"cd0bfb2c-a356-4eb2-8778-870764a834f5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/Omdena School/Solving Business Problems with NLP/Capstone Project\n"]}]},{"cell_type":"code","source":["!pip install -r requirements.txt\n","!pip install pyngrok\n","!pip install streamlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_g0CGNuZJija","executionInfo":{"status":"ok","timestamp":1647693299442,"user_tz":-480,"elapsed":74848,"user":{"displayName":"Gerson Cruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07825640613715802477"}},"outputId":"ddc03ada-c6ee-4b65-9d72-3facb5ef8246"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.3.5)\n","Collecting spacy==2.3.5\n","  Downloading spacy-2.3.5-cp37-cp37m-manylinux2014_x86_64.whl (10.4 MB)\n","\u001b[K     |████████████████████████████████| 10.4 MB 25.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.21.5)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.5)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 58.7 MB/s \n","\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.2.6)\n","Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 67.5 MB/s \n","\u001b[?25hCollecting tensorflow-gpu\n","  Downloading tensorflow_gpu-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n","\u001b[K     |████████████████████████████████| 497.5 MB 28 kB/s \n","\u001b[?25hCollecting bert-extractive-summarizer\n","  Downloading bert_extractive_summarizer-0.10.1-py3-none-any.whl (25 kB)\n","Collecting neuralcoref\n","  Downloading neuralcoref-4.0-cp37-cp37m-manylinux1_x86_64.whl (286 kB)\n","\u001b[K     |████████████████████████████████| 286 kB 72.4 MB/s \n","\u001b[?25hRequirement already satisfied: altair in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (4.2.0)\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (1.7.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (0.11.1+cu111)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 2)) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 2)) (57.4.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 2)) (0.9.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 2)) (1.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 2)) (1.1.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 2)) (2.0.6)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 2)) (4.63.0)\n","Collecting thinc<7.5.0,>=7.4.1\n","  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 61.5 MB/s \n","\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 2)) (2.23.0)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 2)) (0.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 2)) (3.0.6)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.5->-r requirements.txt (line 2)) (1.0.6)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.5->-r requirements.txt (line 2)) (4.11.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5->-r requirements.txt (line 2)) (3.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.5->-r requirements.txt (line 2)) (3.10.0.2)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5->-r requirements.txt (line 2)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5->-r requirements.txt (line 2)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5->-r requirements.txt (line 2)) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.5->-r requirements.txt (line 2)) (3.0.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 7)) (2019.12.20)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.4 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 76.9 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 58.1 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 7)) (21.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 56.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers->-r requirements.txt (line 7)) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers->-r requirements.txt (line 7)) (3.0.7)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (1.1.2)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (0.24.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (2.8.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (3.17.3)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (1.1.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (1.6.3)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (2.8.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (0.2.0)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (0.5.3)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 75.5 MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (3.3.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (1.44.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (1.13.3)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (1.0.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (13.0.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu->-r requirements.txt (line 8)) (3.1.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu->-r requirements.txt (line 8)) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu->-r requirements.txt (line 8)) (1.5.2)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (1.8.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (1.35.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (3.3.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (1.3.1)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow-gpu->-r requirements.txt (line 8)) (3.2.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from bert-extractive-summarizer->-r requirements.txt (line 9)) (1.0.2)\n","Collecting boto3\n","  Downloading boto3-1.21.22-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 75.5 MB/s \n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair->-r requirements.txt (line 11)) (2.11.3)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair->-r requirements.txt (line 11)) (4.3.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair->-r requirements.txt (line 11)) (0.4)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair->-r requirements.txt (line 11)) (0.11.2)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 11)) (21.4.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 11)) (5.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair->-r requirements.txt (line 11)) (0.18.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (7.1.2)\n","Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (3.1.27)\n","Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.8.1)\n","Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.18.2)\n","Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (1.0.1)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (6.0.1)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (7.1.2)\n","Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (2.1.1)\n","Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (2.13.0)\n","Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (1.4)\n","Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.7.1)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (1.5.1)\n","Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (2.1.6)\n","Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (5.1.1)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit->-r requirements.txt (line 12)) (0.10.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit->-r requirements.txt (line 12)) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit->-r requirements.txt (line 12)) (5.0.0)\n","Requirement already satisfied: ipykernel>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (6.9.2)\n","Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (5.1.1)\n","Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (7.6.5)\n","Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.1.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (5.4.8)\n","Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (7.32.0)\n","Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (5.3.5)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (1.5.4)\n","Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (1.0.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.2.0)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (3.0.28)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (4.8.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (2.6.1)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.18.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.7.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (4.4.2)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.2.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (5.1.3)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (3.5.2)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (1.0.2)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.8.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair->-r requirements.txt (line 11)) (2.0.1)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (22.3.0)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (4.9.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.2.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (5.3.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.13.3)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (5.6.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (1.8.0)\n","Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 13)) (1.10.0+cu111)\n","Collecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Collecting botocore<1.25.0,>=1.24.22\n","  Downloading botocore-1.24.22-py3-none-any.whl (8.6 MB)\n","\u001b[K     |████████████████████████████████| 8.6 MB 55.8 MB/s \n","\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 9.9 MB/s \n","\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 81.8 MB/s \n","\u001b[?25hRequirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (4.1.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.8.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (1.5.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.6.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->-r requirements.txt (line 12)) (0.5.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers->-r requirements.txt (line 7)) (1.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer->-r requirements.txt (line 9)) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->bert-extractive-summarizer->-r requirements.txt (line 9)) (3.1.0)\n","Installing collected packages: urllib3, jmespath, pyyaml, botocore, tokenizers, thinc, sacremoses, s3transfer, huggingface-hub, transformers, tf-estimator-nightly, spacy, boto3, tensorflow-gpu, sentencepiece, neuralcoref, bert-extractive-summarizer\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.9.2 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.32.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed bert-extractive-summarizer-0.10.1 boto3-1.21.22 botocore-1.24.22 huggingface-hub-0.4.0 jmespath-1.0.0 neuralcoref-4.0 pyyaml-6.0 s3transfer-0.5.2 sacremoses-0.0.49 sentencepiece-0.1.96 spacy-2.3.5 tensorflow-gpu-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109 thinc-7.4.5 tokenizers-0.11.6 transformers-4.17.0 urllib3-1.25.11\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.1.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.7/dist-packages (1.7.0)\n","Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.3)\n","Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.7.1)\n","Requirement already satisfied: watchdog in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.6)\n","Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.1)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from streamlit) (6.0.1)\n","Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.3.5)\n","Requirement already satisfied: pympler>=0.9 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.0.1)\n","Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.17.3)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.21.5)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.2)\n","Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.13.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.0)\n","Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n","Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.11.2)\n","Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.18.2)\n","Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.1.27)\n","Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.4)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n","Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.10.0.2)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from streamlit) (21.4.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.2)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (4.3.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.4)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython!=3.1.19->streamlit) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (5.0.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->streamlit) (3.7.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (5.4.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.18.1)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n","Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.1.1)\n","Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.5)\n","Requirement already satisfied: ipykernel>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (6.9.2)\n","Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.1.3)\n","Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (7.32.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.4.8)\n","Requirement already satisfied: jupyter-client<8.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (5.3.5)\n","Requirement already satisfied: debugpy<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.0.0)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (1.5.4)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.0.28)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.6.1)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.8.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (57.4.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.1)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.2)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.2)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.3)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.9.2)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client<8.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (22.3.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.8.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.13.3)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (3.0.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2021.10.8)\n"]}]},{"cell_type":"code","source":["%%writefile app.py\n","import streamlit as st\n","def main():\n","\tst.title(\"Awesome Streamlit for ML\")\n","\tst.subheader(\"How to run streamlit from colab\")\n","\tmenu = [\"Home\",\"About\"]\n","\tchoice = st.sidebar.selectbox('Menu',menu)\n","\tif choice == 'Home':\n","\t\tst.subheader(\"Streamlit From Colab\")\t\n","if __name__ == '__main__':\n","\tmain()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eyy-MFqfBuD_","executionInfo":{"status":"ok","timestamp":1647692201512,"user_tz":-480,"elapsed":343,"user":{"displayName":"Gerson Cruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07825640613715802477"}},"outputId":"22d6096b-fe13-4d54-a1ee-2d1302ed4440"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AgpnIBf2CN_H","executionInfo":{"status":"ok","timestamp":1647693305263,"user_tz":-480,"elapsed":471,"user":{"displayName":"Gerson Cruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07825640613715802477"}},"outputId":"fbfb3cc2-f4db-4023-cd64-976533838f39"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":[" abstractive_summarized_text.csv\n"," app.py\n","'Capstone Project - {Gerson Cruz}.ipynb'\n","'Capstone Project Streamlit - {Cruz, Gerson}.ipynb'\n"," extractive_summaries.csv\n"," extractive_summarized_text.csv\n"," __MACOSX\n"," nohup.out\n"," requirements.txt\n"," scisummnet_release1.1__20190413\n"," scisummnet_release1.1__20190413.zip\n"," streamlit_summarizer.py\n","'Text Summarization Image.png'\n"," top100_cleaned.csv\n"," top100.csv\n","'XML Structure.png'\n"]}]},{"cell_type":"code","source":["!streamlit run streamlit_summarizer.py & npx localtunnel --port 8501"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lqh0JEVaBzeH","executionInfo":{"status":"ok","timestamp":1647695530677,"user_tz":-480,"elapsed":2222259,"user":{"displayName":"Gerson Cruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07825640613715802477"}},"outputId":"02e9d19d-067d-45bd-8ffc-efa183d4ff8a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-03-19 12:35:09.516 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n","\u001b[K\u001b[?25hnpx: installed 22 in 2.085s\n","your url is: https://slimy-parrot-26.loca.lt\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.199.39.218:8501\u001b[0m\n","\u001b[0m\n","2022-03-19 12:36:01.074132: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.morphology.Morphology size changed, may indicate binary incompatibility. Expected 104 from C header, got 112 from PyObject\n","  return f(*args, **kwds)\n","/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.vocab.Vocab size changed, may indicate binary incompatibility. Expected 96 from C header, got 112 from PyObject\n","  return f(*args, **kwds)\n","/usr/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.tokens.span.Span size changed, may indicate binary incompatibility. Expected 72 from C header, got 80 from PyObject\n","  return f(*args, **kwds)\n","2022-03-19 12:36:02.790 Getting model from https://s3.amazonaws.com/models.huggingface.co/neuralcoref/neuralcoref.tar.gz or cache\n","2022-03-19 12:36:02.832 https://s3.amazonaws.com/models.huggingface.co/neuralcoref/neuralcoref.tar.gz not found in cache, downloading to /tmp/tmp6lp6r1vy\n","100% 40155833/40155833 [00:00<00:00, 52275813.59B/s]\n","2022-03-19 12:36:03.646 copying /tmp/tmp6lp6r1vy to cache at /root/.neuralcoref_cache/f46bc05a4bfba2ae0d11ffd41c4777683fa78ed357dc04a23c67137abf675e14.7d6f9a6fecf5cf09e74b65f85c7d6896b21decadb2554d486474f63b95ec4633\n","2022-03-19 12:36:03.686 creating metadata file for /root/.neuralcoref_cache/f46bc05a4bfba2ae0d11ffd41c4777683fa78ed357dc04a23c67137abf675e14.7d6f9a6fecf5cf09e74b65f85c7d6896b21decadb2554d486474f63b95ec4633\n","2022-03-19 12:36:03.687 removing temp file /tmp/tmp6lp6r1vy\n","2022-03-19 12:36:03.691 extracting archive file /root/.neuralcoref_cache/f46bc05a4bfba2ae0d11ffd41c4777683fa78ed357dc04a23c67137abf675e14.7d6f9a6fecf5cf09e74b65f85c7d6896b21decadb2554d486474f63b95ec4633 to dir /root/.neuralcoref_cache/neuralcoref\n","https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_xifome2\n","Downloading: 100% 385/385 [00:00<00:00, 507kB/s]\n","storing https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","creating metadata file for /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp_da36z3v\n","Downloading: 100% 223k/223k [00:00<00:00, 19.2MB/s]\n","storing https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n","creating metadata file for /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp2ityhtnu\n","Downloading: 100% 422M/422M [00:10<00:00, 43.0MB/s]\n","storing https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n","creating metadata file for /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n","loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n","Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of BertModel were initialized from the model checkpoint at allenai/scibert_scivocab_uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpt9r2ed34\n","Downloading: 100% 1.55k/1.55k [00:00<00:00, 2.44MB/s]\n","storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","creating metadata file for /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpet9lnzsf\n","Downloading: 100% 1.51G/1.51G [01:45<00:00, 15.5MB/s]\n","storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n","creating metadata file for /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n","loading weights file https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n","All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpajymvpn3\n","Downloading: 100% 878k/878k [00:00<00:00, 23.6MB/s]\n","storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","creating metadata file for /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp7gf04j4r\n","Downloading: 100% 446k/446k [00:00<00:00, 17.3MB/s]\n","storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","creating metadata file for /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmplgg375bl\n","Downloading: 100% 1.29M/1.29M [00:00<00:00, 33.7MB/s]\n","storing https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","creating metadata file for /root/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","Your max_length is set to 750, but you input_length is only 33. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n","Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of BertModel were initialized from the model checkpoint at allenai/scibert_scivocab_uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","loading weights file https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n","All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Your max_length is set to 750, but you input_length is only 93. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=46)\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/33593020f507d72099bd84ea6cd2296feb424fecd62d4a8edcc2a02899af6e29.38339d84e6e392addd730fd85fae32652c4cc7c5423633d6fa73e5f7937bbc38\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer.json from cache at None\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","loading configuration file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/858852fd2471ce39075378592ddc87f5a6551e64c6825d1b92c8dab9318e0fc3.03ff9e9f998b9a9d40647a2148a202e3fb3d568dc0f170dda9dda194bab4d5dd\n","Model config BertConfig {\n","  \"_name_or_path\": \"allenai/scibert_scivocab_uncased\",\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.17.0\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 31090\n","}\n","\n","loading weights file https://huggingface.co/allenai/scibert_scivocab_uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/de14937a851e8180a2bc5660c0041d385f8a0c62b1b2ccafa46df31043a2390c.74830bb01a0ffcdeaed8be9916312726d0c4cd364ac6fc15b375f789eaff4cbb\n","Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of BertModel were initialized from the model checkpoint at allenai/scibert_scivocab_uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","loading weights file https://huggingface.co/facebook/bart-large-cnn/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/4ccdf4cdc01b790f9f9c636c7695b5d443180e8dbd0cbe49e07aa918dda1cef0.fa29468c10a34ef7f6cfceba3b174d3ccc95f8d755c3ca1b829aff41cc92a300\n","All model checkpoint weights were used when initializing BartForConditionalGeneration.\n","\n","All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n","Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/4d8eeedc3498bc73a4b72411ebb3219209b305663632d77a6f16e60790b18038.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/0ddddd3ca9e107b17a6901c92543692272af1c3238a8d7549fa937ba0057bbcf.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/55c96bd962ce1d360fde4947619318f1b4eb551430de678044699cbfeb99de6a.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/facebook/bart-large-cnn/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/facebook/bart-large-cnn/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/199ab6c0f28e763098fd3ea09fd68a0928bb297d0f76b9f3375e8a1d652748f9.930264180d256e6fe8e4ba6a728dd80e969493c23d4caa0a6f943614c52d34ab\n","Model config BartConfig {\n","  \"_name_or_path\": \"facebook/bart-large-cnn\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 12,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"scale_embedding\": false,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.17.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Your max_length is set to 750, but you input_length is only 83. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n","\u001b[34m  Stopping...\u001b[0m\n","^C\n"]}]},{"cell_type":"code","source":["!pgrep streamlit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ELsK2KJCeCK","executionInfo":{"status":"ok","timestamp":1647691508574,"user_tz":-480,"elapsed":260,"user":{"displayName":"Gerson Cruz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07825640613715802477"}},"outputId":"7d4868df-d407-4646-bd15-35ae21e67349"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["390\n"]}]},{"cell_type":"code","source":["# https://purple-snake-18.loca.lt"],"metadata":{"id":"8Uvr6FE5JYx7"},"execution_count":null,"outputs":[]}]}